"""
æ—¥å¿—ç®¡ç†æ¨¡å—ï¼Œæä¾›æ—¥å¿—è®°å½•å’Œæ¸…ç†åŠŸèƒ½
"""
import os
import sys
import logging
from logging.handlers import RotatingFileHandler
import time
from datetime import datetime, timedelta
import glob
import threading
from contextlib import contextmanager
import config

# åˆ›å»ºæ—¥å¿—ç›®å½•
if not os.path.exists('logs'):
    os.makedirs('logs')

# æ—¥å¿—æ–‡ä»¶è·¯å¾„
log_file = os.path.join('logs', config.LOG_FILE)

# æ¨¡å—åç§°æ˜ å°„(ç²¾ç®€æ—¥å¿—è¾“å‡º)
MODULE_NAME_MAP = {
    'position_manager': 'pm',
    'data_manager': 'dm',
    'trading_executor': 'te',
    'strategy': 'st',
    'web_server': 'ws',
    'thread_monitor': 'tm',
    'premarket_sync': 'ps',
    'config_manager': 'cm',
    'indicator_calculator': 'ic',
    'sell_monitor': 'sm',
    'grid_trading_manager': 'gtm',
    'grid_database': 'gdb',
    'main': 'main',
}

# æ—¥å¿—æ ¼å¼(ä¼˜åŒ–: ä½¿ç”¨å•å­—æ¯çº§åˆ«,ç²¾ç®€æ¨¡å—å)
log_formatter = logging.Formatter('%(asctime)s [%(levelname).1s] %(name)s - %(message)s')

# åˆ›å»ºæ—¥å¿—å¤„ç†å™¨
file_handler = RotatingFileHandler(
    log_file,
    encoding='utf-8',  # æŒ‡å®šç¼–ç ä¸º UTF-8
    maxBytes=config.LOG_MAX_SIZE, 
    backupCount=config.LOG_BACKUP_COUNT
)
file_handler.setFormatter(log_formatter)

# æ§åˆ¶å°å¤„ç†å™¨ - æ·»åŠ é”™è¯¯å¤„ç†,é¿å…ç¨‹åºé€€å‡ºæ—¶çš„I/Oé”™è¯¯
class SafeStreamHandler(logging.StreamHandler):
    """å®‰å…¨çš„StreamHandler,æ•è·I/Oé”™è¯¯

    ä¸»è¦è§£å†³ä¸¤ä¸ªé—®é¢˜:
    1. ç¨‹åºé€€å‡ºæ—¶coloramaå…³é—­wrapped stdoutå¯¼è‡´çš„I/Oé”™è¯¯
    2. å¤šçº¿ç¨‹ç¯å¢ƒä¸‹(å¦‚Flask WebæœåŠ¡å™¨)çš„æ—¥å¿—ç«æ€æ¡ä»¶
    """
    def emit(self, record):
        try:
            super().emit(record)
        except (ValueError, OSError, AttributeError):
            # å¿½ç•¥ä»¥ä¸‹é”™è¯¯:
            # - ValueError: I/O operation on closed file (coloramaå…³é—­stdout)
            # - OSError: æ–‡ä»¶æè¿°ç¬¦æ— æ•ˆ
            # - AttributeError: å¯¹è±¡å±æ€§ä¸å­˜åœ¨(æå°‘è§)
            # è¿™äº›é”™è¯¯é€šå¸¸å‘ç”Ÿåœ¨ç¨‹åºé€€å‡ºæˆ–çº¿ç¨‹æ¸…ç†æ—¶,ä¸å½±å“åŠŸèƒ½
            pass
        except Exception:
            # æ•è·å…¶ä»–æ‰€æœ‰å¼‚å¸¸,é¿å…æ—¥å¿—é”™è¯¯å¯¼è‡´ç¨‹åºå´©æºƒ
            # æ³¨æ„: è¿™é‡Œä¸èƒ½ä½¿ç”¨loggerè®°å½•(ä¼šå¯¼è‡´é€’å½’),æ‰€ä»¥é™é»˜å¤„ç†
            pass

# ğŸ”§ å…³é”®ä¿®å¤: Monkey patch logging.StreamHandler.emitæ–¹æ³•
# è¿™æ ·æ‰€æœ‰ä½¿ç”¨StreamHandlerçš„logger(åŒ…æ‹¬werkzeug)éƒ½èƒ½å®‰å…¨å¤„ç†I/Oé”™è¯¯
_original_stream_handler_emit = logging.StreamHandler.emit

def _safe_emit(self, record):
    """å®‰å…¨çš„emitæ–¹æ³•,æ•è·I/Oå¼‚å¸¸"""
    try:
        _original_stream_handler_emit(self, record)
    except (ValueError, OSError, AttributeError):
        # é™é»˜å¤„ç†I/Oé”™è¯¯
        pass
    except Exception:
        # æ•è·æ‰€æœ‰å…¶ä»–å¼‚å¸¸
        pass

# æ›¿æ¢logging.StreamHandlerçš„emitæ–¹æ³•
logging.StreamHandler.emit = _safe_emit

console_handler = SafeStreamHandler()
console_handler.setFormatter(log_formatter)

# åˆ›å»ºlogger
logger = logging.getLogger('miniQMT')
logger.setLevel(getattr(logging, config.LOG_LEVEL))
logger.addHandler(file_handler)
logger.addHandler(console_handler)

# è®¾ç½®è°ƒè¯•æ¨¡å¼ä¸‹çš„è¯¦ç»†æ—¥å¿—
if config.DEBUG:
    logger.setLevel(logging.DEBUG)

def get_logger(name=None):
    """è·å–æŒ‡å®šåç§°çš„logger,è‡ªåŠ¨åº”ç”¨æ¨¡å—åç§°æ˜ å°„"""
    if name:
        # åº”ç”¨æ¨¡å—åç§°æ˜ å°„
        short_name = MODULE_NAME_MAP.get(name, name)
        child_logger = logger.getChild(short_name)
        return child_logger
    return logger

def clean_old_logs(days=None):
    """æ¸…ç†æŒ‡å®šå¤©æ•°å‰çš„æ—¥å¿—æ–‡ä»¶"""
    if days is None:
        days = config.LOG_CLEANUP_DAYS

    logger.info(f"æ¸…ç†{days}å¤©å‰æ—¥å¿—")

    # è·å–å½“å‰æ—¥æœŸ
    current_date = datetime.now()

    # è®¡ç®—æˆªæ­¢æ—¥æœŸ
    cutoff_date = current_date - timedelta(days=days)
    cutoff_timestamp = cutoff_date.timestamp()

    # è·å–æ—¥å¿—ç›®å½•ä¸‹çš„æ‰€æœ‰æ—¥å¿—æ–‡ä»¶
    log_pattern = os.path.join('logs', '*.log*')
    log_files = glob.glob(log_pattern)

    # æ£€æŸ¥æ¯ä¸ªæ—¥å¿—æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´
    for log_file in log_files:
        file_mtime = os.path.getmtime(log_file)
        if file_mtime < cutoff_timestamp:
            try:
                os.remove(log_file)
                logger.info(f"åˆ é™¤æ—§æ—¥å¿—: {os.path.basename(log_file)}")
            except Exception as e:
                logger.error(f"åˆ é™¤å¤±è´¥: {os.path.basename(log_file)} - {str(e)[:30]}")

    logger.info("æ—¥å¿—æ¸…ç†å®Œæˆ")

def schedule_log_cleanup():
    """å®šæ—¶æ¸…ç†æ—¥å¿—"""
    if not config.ENABLE_LOG_CLEANUP:
        return

    while True:
        # è·å–å½“å‰æ—¶é—´
        now = datetime.now()
        cleanup_time = datetime.strptime(config.LOG_CLEANUP_TIME, "%H:%M:%S").time()

        # å¦‚æœå½“å‰æ—¶é—´æ˜¯æ¸…ç†æ—¶é—´ï¼Œæ‰§è¡Œæ¸…ç†
        if now.time().hour == cleanup_time.hour and now.time().minute == cleanup_time.minute:
            clean_old_logs()
            # ç­‰å¾…60ç§’ï¼Œé¿å…åœ¨åŒä¸€åˆ†é’Ÿå†…å¤šæ¬¡æ‰§è¡Œ
            time.sleep(60)
        else:
            # ç­‰å¾…10åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
            time.sleep(600)

# ============ ç¬¬ä¸‰æ–¹åº“è¾“å‡ºæŠ‘åˆ¶å·¥å…· ============

_stdout_lock = threading.Lock()

@contextmanager
def suppress_stdout_stderr():
    """
    ä¼˜é›…åœ°æŠ‘åˆ¶æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯è¾“å‡º

    ç”¨é€”ï¼šæŸäº›ç¬¬ä¸‰æ–¹åº“ï¼ˆå¦‚baostockï¼‰ä¼šç›´æ¥æ‰“å°åˆ°stdoutï¼Œ
         ä½¿ç”¨æ­¤ä¸Šä¸‹æ–‡ç®¡ç†å™¨å¯ä»¥ä¸´æ—¶æŠ‘åˆ¶è¿™äº›è¾“å‡ºã€‚

    ç‰¹æ€§ï¼š
    - çº¿ç¨‹å®‰å…¨ï¼ˆä½¿ç”¨é”ä¿æŠ¤ï¼‰
    - å¼‚å¸¸å®‰å…¨ï¼ˆç¡®ä¿stdout/stderrä¸€å®šæ¢å¤ï¼‰
    - è·¨å¹³å°å…¼å®¹

    ç¤ºä¾‹ï¼š
        with suppress_stdout_stderr():
            lg = bs.login()  # ä¸ä¼šæ‰“å° "login success!"
    """
    with _stdout_lock:
        # ä¿å­˜åŸå§‹çš„ stdout å’Œ stderr
        old_stdout = sys.stdout
        old_stderr = sys.stderr

        try:
            # é‡å®šå‘åˆ° devnull
            with open(os.devnull, 'w') as devnull:
                sys.stdout = devnull
                sys.stderr = devnull
                yield
        finally:
            # æ¢å¤åŸå§‹çš„ stdout å’Œ stderr
            sys.stdout = old_stdout
            sys.stderr = old_stderr
